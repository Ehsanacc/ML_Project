{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51sbiNZiEQdF"
      },
      "source": [
        "***Simulation Question 4:***\n",
        "\n",
        "Use 80 percent of the CIFAR-10 training data to train your model.\n",
        "This will serve as your baseline model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w8sFvZeEVJ7"
      },
      "source": [
        "**Importing needed libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTwlwWCa5t22"
      },
      "outputs": [],
      "source": [
        "# Importing the libraries\n",
        "from random import shuffle\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression as LR\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQknFxkKEX_Q"
      },
      "source": [
        "**Given base model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aj607fEV7APj"
      },
      "outputs": [],
      "source": [
        "class CIFAR10Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CIFAR10Classifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(6272, 64)\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuUcSMCQEdpP"
      },
      "source": [
        "**Define Load data to get the needed Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0BJe2Su6yMu",
        "outputId": "a402c1f8-8bc6-4742-d3c2-ca136db26847"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to dataset/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 44334842.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/cifar-10-python.tar.gz to dataset\n",
            "Files already downloaded and verified\n",
            "704\n",
            "79\n",
            "157\n"
          ]
        }
      ],
      "source": [
        "def get_data():\n",
        "    # CIFAR-10 dataset mean and standard deviation\n",
        "    cifar10_mean = np.array([0.49421428, 0.48513139, 0.45040909])\n",
        "    cifar10_std = np.array([0.24665252, 0.24289226, 0.26159238])\n",
        "\n",
        "    # CIFAR-10 dataset transforms\n",
        "    transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cifar10_mean, cifar10_std),\n",
        "    ])\n",
        "\n",
        "    # CIFAR-10 dataset transforms\n",
        "    transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cifar10_mean, cifar10_std),\n",
        "    ])\n",
        "\n",
        "    # Unnormalize transform for CIFAR-10 dataset\n",
        "    unnormalize_transform = transforms.Normalize(-cifar10_mean/cifar10_std, 1/cifar10_std)\n",
        "\n",
        "    # CIFAR-10 dataset loading\n",
        "    cifar10_dataset = datasets.CIFAR10(root='dataset', train=True, download=True, transform=transform_train)\n",
        "    train_dataset, val_dataset = random_split(cifar10_dataset, [45000, 5000])\n",
        "    test_dataset = datasets.CIFAR10(root='dataset', train=False, download=True, transform=transform_test)\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(dataset=val_dataset, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "train_loader, val_loader, test_loader = get_data()\n",
        "print(len(train_loader))\n",
        "print(len(val_loader))\n",
        "print(len(test_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**define model_train function**"
      ],
      "metadata": {
        "id": "kWMeBvzYq-W-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZaCr9rrAFBn"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def model_train(model, train_loader, val_loader, criterion, num_epochs, regularization_strength = None, model_name = None):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    if regularization_strength == None:\n",
        "        regularization_strength = 0\n",
        "\n",
        "    train_loss_arr, val_loss_arr = [], []\n",
        "    train_acc_arr, val_acc_arr = [], []\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, val_loss = .0, .0\n",
        "        train_acc, val_acc = .0, .0\n",
        "\n",
        "        model.train()\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            l2_reg = sum(torch.sum(param ** 2) for param in model.parameters())\n",
        "            loss += regularization_strength * l2_reg\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            train_acc += torch.sum(torch.max(outputs, axis=1)[1] == labels).cpu().item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                l2_reg = sum(torch.sum(param ** 2) for param in model.parameters())\n",
        "                loss += regularization_strength * l2_reg\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                val_acc += torch.sum(torch.max(outputs, axis=1)[1] == labels).cpu().item()\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        train_acc /= len(train_loader.dataset)\n",
        "        val_acc /= len(val_loader.dataset)\n",
        "\n",
        "        train_loss_arr.append(train_loss)\n",
        "        val_loss_arr.append(val_loss)\n",
        "        train_acc_arr.append(train_acc)\n",
        "        val_acc_arr.append(val_acc)\n",
        "\n",
        "        print(f\"[Epoch {epoch}]\\t\"\n",
        "            f\"[{datetime.now().strftime('%H:%M:%S')}]\\t\"\n",
        "            f\"Train Loss: {train_loss:.4f}\\t\"\n",
        "            f\"Train Accuracy: {train_acc:.2f}\\t\"\n",
        "            f\"Validation Loss: {val_loss:.4f}\\t\\t\"\n",
        "            f\"Validation Accuracy: {val_acc:.2f}\")\n",
        "        torch.save(model.state_dict(), f'{model_name}.pth')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the base line model using the given data in this section**"
      ],
      "metadata": {
        "id": "Nf16kIRvi6eW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CIFAR10Classifier().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "num_epochs=10\n",
        "\n",
        "model_train(model, train_loader, val_loader, criterion, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ai1gpmaqSDZj",
        "outputId": "e2b2c952-fe7b-4aaf-f2aa-125163c08f62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0]\t[23:41:17]\tTrain Loss: 1.8088\tTrain Accuracy: 0.33\tValidation Loss: 1.5114\t\tValidation Accuracy: 0.45\n",
            "[Epoch 1]\t[23:41:40]\tTrain Loss: 1.5788\tTrain Accuracy: 0.42\tValidation Loss: 1.3684\t\tValidation Accuracy: 0.51\n",
            "[Epoch 2]\t[23:42:05]\tTrain Loss: 1.4768\tTrain Accuracy: 0.46\tValidation Loss: 1.2742\t\tValidation Accuracy: 0.55\n",
            "[Epoch 3]\t[23:42:28]\tTrain Loss: 1.4160\tTrain Accuracy: 0.48\tValidation Loss: 1.2144\t\tValidation Accuracy: 0.57\n",
            "[Epoch 4]\t[23:42:52]\tTrain Loss: 1.3678\tTrain Accuracy: 0.51\tValidation Loss: 1.2056\t\tValidation Accuracy: 0.58\n",
            "[Epoch 5]\t[23:43:15]\tTrain Loss: 1.3416\tTrain Accuracy: 0.52\tValidation Loss: 1.1426\t\tValidation Accuracy: 0.59\n",
            "[Epoch 6]\t[23:43:38]\tTrain Loss: 1.3214\tTrain Accuracy: 0.53\tValidation Loss: 1.1378\t\tValidation Accuracy: 0.60\n",
            "[Epoch 7]\t[23:44:02]\tTrain Loss: 1.3112\tTrain Accuracy: 0.53\tValidation Loss: 1.1135\t\tValidation Accuracy: 0.61\n",
            "[Epoch 8]\t[23:44:25]\tTrain Loss: 1.2937\tTrain Accuracy: 0.54\tValidation Loss: 1.1192\t\tValidation Accuracy: 0.61\n",
            "[Epoch 9]\t[23:44:48]\tTrain Loss: 1.2837\tTrain Accuracy: 0.54\tValidation Loss: 1.1160\t\tValidation Accuracy: 0.61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check model accuracy on test_loader**"
      ],
      "metadata": {
        "id": "BJQWPhiOl18k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THOcEwiiEaBv",
        "outputId": "dfc05ce0-eae9-4a40-e50f-11933848fb4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 64.99%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on the test set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QJI9vuDEjTs"
      },
      "source": [
        "**Training phase**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNvQO-J5XXBI"
      },
      "source": [
        "***Simulation Question 5:***\n",
        "\n",
        "Train your baseline model with privacy enhancements. This is your\n",
        "modified model. Ensure that the test accuracy difference between your baseline model and the\n",
        "modified model is less than 15\n",
        "\n",
        "**Methods used for privacy enhancements:**\n",
        "\n",
        "    rounding output of model to 3 digits\n",
        "    Restriction of prediction vector to top 3 elements\n",
        "    Using regulatization term λ||Θ||\n",
        "\n",
        "**These methods help the model leak less information when classifying**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNKly3PGXe8o"
      },
      "outputs": [],
      "source": [
        "class Private_CIFAR10Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Private_CIFAR10Classifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Calculate the input size for the fully connected layer\n",
        "        self._to_linear = None\n",
        "        self._get_conv_output_size()\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 64)\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "    def _get_conv_output_size(self):\n",
        "        x = torch.rand(1, 3, 32, 32)\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout1(x)\n",
        "        self._to_linear = x.numel()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        # only giving top k values\n",
        "        k = 2\n",
        "        topk_values, topk_indices = torch.topk(x, k, dim=1)\n",
        "        mask = torch.zeros_like(x)\n",
        "        mask.scatter_(1, topk_indices, topk_values)\n",
        "\n",
        "        # Round the values in the mask to 3 decimal places\n",
        "        rounded_mask = torch.round(mask * 100) / 100\n",
        "\n",
        "        return mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Start training phase for the new model created as private model from the same data had from earlier**"
      ],
      "metadata": {
        "id": "lyhv5JNAmMPB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "-ARn1olN8Pb6",
        "outputId": "728e80fd-e3bc-4041-cb27-3006a2153efc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0]\t[09:09:00]\tTrain Loss: 2.2165\tTrain Accuracy: 0.26\tValidation Loss: 2.1201\t\tValidation Accuracy: 0.31\n",
            "[Epoch 1]\t[09:10:17]\tTrain Loss: 2.0763\tTrain Accuracy: 0.33\tValidation Loss: 2.0028\t\tValidation Accuracy: 0.37\n",
            "[Epoch 2]\t[09:15:12]\tTrain Loss: 2.0352\tTrain Accuracy: 0.35\tValidation Loss: 1.9737\t\tValidation Accuracy: 0.38\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-67dc78367dff>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_strength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-47558dcddf60>\u001b[0m in \u001b[0;36mmodel_train\u001b[0;34m(model, train_loader, val_loader, criterion, num_epochs, regularization_strength, model_name)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0ml2_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-7eb494894bed>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = Private_CIFAR10Classifier().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "regularization_strength = 5e-3  # Start with a small regularization strength\n",
        "num_epochs = 10\n",
        "\n",
        "model_train(model, train_loader, val_loader, criterion, num_epochs, regularization_strength)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check private model accuracy on the test_loader**"
      ],
      "metadata": {
        "id": "5cI2rXG2mTrL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA0qg3BjEM9Z",
        "outputId": "a4b05532-0adc-4aee-ad11-38d49eff3964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 17.4%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on the test set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Simulation Question 6.***\n",
        "\n",
        "**Train two Attacker Models based on MIA techniques learned\n",
        "in Phase 0, one for the baseline model and one for the modified model. Compare the MIA\n",
        "accuracy of these two attacker models. Use 80 percent of the training data as your seen data,\n",
        "and the remaining training data along with the test data as your unseen data**"
      ],
      "metadata": {
        "id": "DHQdWRjNtTY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a shadow model to mimic the target model**"
      ],
      "metadata": {
        "id": "IbcihSJgmdB1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRQX2JwchHLA"
      },
      "outputs": [],
      "source": [
        "class ShadowModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ShadowModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(6272, 64)\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        return F.softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**create private shadow model to mimic private model**"
      ],
      "metadata": {
        "id": "_6xrCdYTr5de"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Private_ShadowModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Private_ShadowModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Calculate the input size for the fully connected layer\n",
        "        self._to_linear = None\n",
        "        self._get_conv_output_size()\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 64)\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "    def _get_conv_output_size(self):\n",
        "        x = torch.rand(1, 3, 32, 32)\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout1(x)\n",
        "        self._to_linear = x.numel()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        # only giving top k values\n",
        "        k = 2\n",
        "        topk_values, topk_indices = torch.topk(x, k, dim=1)\n",
        "        mask = torch.zeros_like(x)\n",
        "        mask.scatter_(1, topk_indices, topk_values)\n",
        "\n",
        "        # Round the values in the mask to 3 decimal places\n",
        "        rounded_mask = torch.round(mask * 100) / 100\n",
        "\n",
        "        return mask\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oZnhEfGBZNNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train shadow model in this section for base line model**"
      ],
      "metadata": {
        "id": "X9XN9GipvQXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train 10 different shadow models, each with its corresponding label dataset\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "shadow_model = ShadowModel().to(device)\n",
        "num_epochs = 5\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "print(f\"Training shadow model ...\")\n",
        "model_train(shadow_model, train_loader, val_loader, criterion, num_epochs)\n",
        "\n",
        "# Save the shadow models\n",
        "torch.save(shadow_model.state_dict(), f'shadow_model_Q6.pth')\n",
        "\n",
        "# Example: Print summary of one shadow model\n",
        "print(shadow_model)"
      ],
      "metadata": {
        "id": "LuQAHcxNtU-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create datas suitable for tranining the Attacker model these datas are created by using main datas on shadow models that mimic the target model**"
      ],
      "metadata": {
        "id": "MJTdhRXlvkQF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab689c98-6993-4dd1-ee85-4026d15c300a",
        "id": "r9HbnBVLvkQG"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded shadow models: dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Function to combine inputs and outputs into new dataset entries\n",
        "def create_combined_data(shadow_models, loaders_by_label, mode):\n",
        "    for label in range(10):\n",
        "        shadow_model = shadow_models[label]\n",
        "        shadow_model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, true_outputs in loaders_by_label[label]:\n",
        "                images = images.to(device)\n",
        "                outputs = shadow_model(images).cpu()\n",
        "                for true_output, output in zip(true_outputs, outputs):\n",
        "                    true_output, output = true_output.to(device), output.to(device)\n",
        "                    # Ensure true_output and output have the same number of dimensions\n",
        "                    if true_output.dim() == 0:  # Handle scalar tensor case\n",
        "                        true_output = true_output.unsqueeze(0)\n",
        "                    if output.dim() > 1:  # Handle higher-dimensional output tensor\n",
        "                        output = output.squeeze()  # Adjust dimensions as needed\n",
        "                    combined_output = torch.cat((true_output, output), dim=0)\n",
        "                    yield (combined_output, mode)\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "# Initialize the dictionary for the shadow models\n",
        "shadow_models = {}\n",
        "\n",
        "model_dir = './'\n",
        "\n",
        "# Load shadow models\n",
        "for i in range(10):\n",
        "    model_path = os.path.join(model_dir, f'shadow_model_{i}.pth')\n",
        "    shadow_model = ShadowModel().to(device)\n",
        "    shadow_model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    shadow_model.eval()  # Set the model to evaluation mode\n",
        "    shadow_models[i] = shadow_model\n",
        "\n",
        "# Example: Print the keys of the shadow_models dictionary to verify\n",
        "print(\"Loaded shadow models:\", shadow_models.keys())\n",
        "\n",
        "# Create seen data\n",
        "combined_in_data1 = list(create_combined_data(shadow_models, train_loaders_by_label, 1))\n",
        "combined_in_data2 = list(create_combined_data(shadow_models, val_loaders_by_label, 1))\n",
        "combined_in_data = combined_in_data1 + combined_in_data2\n",
        "\n",
        "# Create unseen data\n",
        "combined_out_data = list(create_combined_data(shadow_models, test_loaders_by_label, -1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Simulation Question 7.***\n",
        "\n",
        "**Improve your attacker models to achieve better MIA accuracy for\n",
        "both the baseline and modified models (e.g., by increasing the number of shadow models).\n",
        "Then compare the new accuracies with the previous results.**"
      ],
      "metadata": {
        "id": "DsBTv8BrtBQO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split data based on their true outputs in order to train shadow models using the new seperated dataset**"
      ],
      "metadata": {
        "id": "2l3KGZuAnEbM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2q7WMfa1hO_M",
        "outputId": "0470fe76-8a52-4b14-dd73-54e11e62a64e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "# Function to split dataset into parts based on labels\n",
        "def split_dataset_by_labels(loader, num_labels=10):\n",
        "    split_datasets = {i: [] for i in range(num_labels)}\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        for i in range(num_labels):\n",
        "            mask = (labels == i)\n",
        "            if mask.any():\n",
        "                split_datasets[i].append((images[mask], labels[mask]))\n",
        "\n",
        "    # Concatenate tensors within each label\n",
        "    for label in split_datasets:\n",
        "        if split_datasets[label]:\n",
        "            images_list, labels_list = zip(*split_datasets[label])\n",
        "            split_datasets[label] = TensorDataset(torch.cat(images_list), torch.cat(labels_list))\n",
        "        else:\n",
        "            split_datasets[label] = TensorDataset(torch.empty(0, 3, 32, 32), torch.empty(0, dtype=torch.long))\n",
        "\n",
        "    return split_datasets\n",
        "\n",
        "# Create data loaders for each label\n",
        "train_loaders_by_label = {i: DataLoader(split_dataset_by_labels(train_loader)[i], batch_size=64, shuffle=False) for i in range(10)}\n",
        "print('1')\n",
        "val_loaders_by_label = {i: DataLoader(split_dataset_by_labels(val_loader)[i], batch_size=64, shuffle=False) for i in range(10)}\n",
        "print('2')\n",
        "test_loaders_by_label = {i: DataLoader(split_dataset_by_labels(test_loader)[i], batch_size=64, shuffle=False) for i in range(10)}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Verify dataloaders have been split and see their shapes**"
      ],
      "metadata": {
        "id": "J9hlNy_jnLyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Print the size of each label's dataset\n",
        "for i in range(10):\n",
        "    print(f\"Label {i}: Train dataset size = {len(train_loaders_by_label[i])}, Val dataset size = {len(val_loaders_by_label[i])}, Test dataset size = {len(test_loaders_by_label[i])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-FYCbsKSE8G",
        "outputId": "f93e2310-d76d-4f0b-972f-b9e72bb71324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label 0: Train dataset size = 70, Val dataset size = 9, Test dataset size = 16\n",
            "Label 1: Train dataset size = 71, Val dataset size = 8, Test dataset size = 16\n",
            "Label 2: Train dataset size = 71, Val dataset size = 8, Test dataset size = 16\n",
            "Label 3: Train dataset size = 71, Val dataset size = 8, Test dataset size = 16\n",
            "Label 4: Train dataset size = 71, Val dataset size = 8, Test dataset size = 16\n",
            "Label 5: Train dataset size = 71, Val dataset size = 8, Test dataset size = 16\n",
            "Label 6: Train dataset size = 71, Val dataset size = 8, Test dataset size = 16\n",
            "Label 7: Train dataset size = 71, Val dataset size = 8, Test dataset size = 16\n",
            "Label 8: Train dataset size = 71, Val dataset size = 8, Test dataset size = 16\n",
            "Label 9: Train dataset size = 71, Val dataset size = 8, Test dataset size = 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train shadow models and save them**"
      ],
      "metadata": {
        "id": "WANndorCpRhC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZwxaAgzjTSn",
        "outputId": "1d2af2fa-78f7-49ce-db29-abd5246d1c1f",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training shadow model for label 0...\n",
            "[Epoch 0]\t[23:52:02]\tTrain Loss: 1.4850\tTrain Accuracy: 0.99\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 1]\t[23:52:02]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 2]\t[23:52:02]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 3]\t[23:52:03]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 4]\t[23:52:03]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "Training shadow model for label 1...\n",
            "[Epoch 0]\t[23:52:03]\tTrain Loss: 1.4845\tTrain Accuracy: 0.99\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 1]\t[23:52:04]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 2]\t[23:52:04]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 3]\t[23:52:05]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 4]\t[23:52:05]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "Training shadow model for label 2...\n",
            "[Epoch 0]\t[23:52:05]\tTrain Loss: 1.4887\tTrain Accuracy: 0.99\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 1]\t[23:52:06]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 2]\t[23:52:06]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 3]\t[23:52:06]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 4]\t[23:52:06]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "Training shadow model for label 3...\n",
            "[Epoch 0]\t[23:52:07]\tTrain Loss: 1.4910\tTrain Accuracy: 0.98\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 1]\t[23:52:07]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 2]\t[23:52:07]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 3]\t[23:52:08]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 4]\t[23:52:08]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "Training shadow model for label 4...\n",
            "[Epoch 0]\t[23:52:08]\tTrain Loss: 1.4789\tTrain Accuracy: 0.99\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 1]\t[23:52:08]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 2]\t[23:52:09]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 3]\t[23:52:09]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 4]\t[23:52:09]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "Training shadow model for label 5...\n",
            "[Epoch 0]\t[23:52:10]\tTrain Loss: 1.4882\tTrain Accuracy: 0.99\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 1]\t[23:52:10]\tTrain Loss: 1.4616\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 2]\t[23:52:10]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 3]\t[23:52:11]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 4]\t[23:52:11]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "Training shadow model for label 6...\n",
            "[Epoch 0]\t[23:52:11]\tTrain Loss: 1.4930\tTrain Accuracy: 0.99\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 1]\t[23:52:11]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 2]\t[23:52:12]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 3]\t[23:52:12]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 4]\t[23:52:12]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "Training shadow model for label 7...\n",
            "[Epoch 0]\t[23:52:13]\tTrain Loss: 1.4858\tTrain Accuracy: 0.99\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 1]\t[23:52:13]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 2]\t[23:52:13]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 3]\t[23:52:13]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 4]\t[23:52:14]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "Training shadow model for label 8...\n",
            "[Epoch 0]\t[23:52:14]\tTrain Loss: 1.4979\tTrain Accuracy: 0.98\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 1]\t[23:52:14]\tTrain Loss: 1.4613\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 2]\t[23:52:15]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 3]\t[23:52:15]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 4]\t[23:52:15]\tTrain Loss: 1.4615\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "Training shadow model for label 9...\n",
            "[Epoch 0]\t[23:52:16]\tTrain Loss: 1.4815\tTrain Accuracy: 0.99\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 1]\t[23:52:16]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 2]\t[23:52:17]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 3]\t[23:52:17]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "[Epoch 4]\t[23:52:17]\tTrain Loss: 1.4612\tTrain Accuracy: 1.00\tValidation Loss: 1.4612\t\tValidation Accuracy: 1.00\n",
            "ShadowModel(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (dropout1): Dropout(p=0.25, inplace=False)\n",
            "  (dropout2): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=6272, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Train 10 different shadow models, each with its corresponding label dataset\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "shadow_models = {}\n",
        "num_epochs = 5\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for label in range(10):\n",
        "    shadow_model = ShadowModel().to(device)\n",
        "    print(f\"Training shadow model for label {label}...\")\n",
        "    model_train(shadow_model, train_loaders_by_label[label], val_loaders_by_label[label], criterion, num_epochs)\n",
        "    shadow_models[label] = shadow_model\n",
        "\n",
        "# Save the shadow models\n",
        "for label in range(10):\n",
        "    torch.save(shadow_models[label].state_dict(), f'shadow_model_{label}.pth')\n",
        "\n",
        "# Example: Print summary of one shadow model\n",
        "print(shadow_models[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create datas suitable for tranining the Attacker model these datas are created by using main datas on shadow models that mimic the target model**"
      ],
      "metadata": {
        "id": "0zjl9I_4yoT5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CzpW3ZWNh-Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab689c98-6993-4dd1-ee85-4026d15c300a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded shadow models: dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Function to combine inputs and outputs into new dataset entries\n",
        "def create_combined_data(shadow_models, loaders_by_label, mode):\n",
        "    for label in range(10):\n",
        "        shadow_model = shadow_models[label]\n",
        "        shadow_model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, true_outputs in loaders_by_label[label]:\n",
        "                images = images.to(device)\n",
        "                outputs = shadow_model(images).cpu()\n",
        "                for true_output, output in zip(true_outputs, outputs):\n",
        "                    true_output, output = true_output.to(device), output.to(device)\n",
        "                    # Ensure true_output and output have the same number of dimensions\n",
        "                    if true_output.dim() == 0:  # Handle scalar tensor case\n",
        "                        true_output = true_output.unsqueeze(0)\n",
        "                    if output.dim() > 1:  # Handle higher-dimensional output tensor\n",
        "                        output = output.squeeze()  # Adjust dimensions as needed\n",
        "                    combined_output = torch.cat((true_output, output), dim=0)\n",
        "                    yield (combined_output, mode)\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "# Initialize the dictionary for the shadow models\n",
        "shadow_models = {}\n",
        "\n",
        "model_dir = './'\n",
        "\n",
        "# Load shadow models\n",
        "for i in range(10):\n",
        "    model_path = os.path.join(model_dir, f'shadow_model_{i}.pth')\n",
        "    shadow_model = ShadowModel().to(device)\n",
        "    shadow_model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    shadow_model.eval()  # Set the model to evaluation mode\n",
        "    shadow_models[i] = shadow_model\n",
        "\n",
        "# Example: Print the keys of the shadow_models dictionary to verify\n",
        "print(\"Loaded shadow models:\", shadow_models.keys())\n",
        "\n",
        "# Create seen data\n",
        "combined_in_data1 = list(create_combined_data(shadow_models, train_loaders_by_label, 1))\n",
        "combined_in_data2 = list(create_combined_data(shadow_models, val_loaders_by_label, 1))\n",
        "combined_in_data = combined_in_data1 + combined_in_data2\n",
        "\n",
        "# Create unseen data\n",
        "combined_out_data = list(create_combined_data(shadow_models, test_loaders_by_label, -1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Print a few sample datas to see their looks**"
      ],
      "metadata": {
        "id": "dFjxC0mUyza6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Print first few entries of each data\n",
        "for i in range(5):\n",
        "    input_data, label = combined_in_data[i]\n",
        "    print(f\"Input: {input_data}, Label: {label}\")\n",
        "\n",
        "for i in range(5):\n",
        "    input_data, label = combined_out_data[i]\n",
        "    print(f\"Input: {input_data}, Label: {label}\")\n",
        "\n",
        "print(len(combined_in_data))\n",
        "print(len(combined_out_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LThs6kW9BJbk",
        "outputId": "8205338c-a3f2-4e94-f7fa-5ab3c4d52c5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: tensor([0.0000e+00, 1.0000e+00, 6.4908e-36, 8.6705e-40, 6.4716e-37, 4.3246e-33,\n",
            "        4.5849e-40, 7.0012e-38, 9.4511e-40, 2.2673e-36, 4.2039e-45],\n",
            "       device='cuda:0'), Label: 1\n",
            "Input: tensor([0.0000e+00, 1.0000e+00, 1.8384e-39, 1.1210e-43, 1.4268e-40, 1.5921e-36,\n",
            "        1.0930e-43, 7.7408e-42, 2.1720e-43, 6.0685e-40, 0.0000e+00],\n",
            "       device='cuda:0'), Label: 1\n",
            "Input: tensor([0.0000e+00, 1.0000e+00, 4.5651e-25, 9.2733e-28, 8.9754e-26, 3.6450e-23,\n",
            "        7.6139e-28, 1.6806e-26, 1.1567e-27, 2.3961e-25, 2.0441e-31],\n",
            "       device='cuda:0'), Label: 1\n",
            "Input: tensor([0.0000e+00, 1.0000e+00, 4.0455e-30, 2.2786e-33, 6.2865e-31, 7.2405e-28,\n",
            "        2.4053e-33, 6.8057e-32, 3.6128e-33, 1.6926e-30, 1.0643e-37],\n",
            "       device='cuda:0'), Label: 1\n",
            "Input: tensor([0.0000e+00, 1.0000e+00, 4.9468e-25, 9.0966e-28, 1.0268e-25, 4.1889e-23,\n",
            "        9.4592e-28, 1.9552e-26, 1.2167e-27, 2.5655e-25, 2.3409e-31],\n",
            "       device='cuda:0'), Label: 1\n",
            "Input: tensor([0.0000e+00, 1.0000e+00, 1.8301e-34, 3.5518e-38, 2.1303e-35, 7.9324e-32,\n",
            "        3.2353e-38, 2.0977e-36, 6.1365e-38, 7.5660e-35, 3.9236e-43],\n",
            "       device='cuda:0'), Label: -1\n",
            "Input: tensor([0.0000e+00, 1.0000e+00, 9.1111e-34, 2.4215e-37, 1.0335e-34, 3.4168e-31,\n",
            "        1.7233e-37, 1.1424e-35, 3.0094e-37, 3.6383e-34, 2.6919e-42],\n",
            "       device='cuda:0'), Label: -1\n",
            "Input: tensor([0.0000e+00, 1.0000e+00, 1.3297e-25, 2.5811e-28, 2.4823e-26, 1.0358e-23,\n",
            "        2.3834e-28, 4.5255e-27, 3.4817e-28, 6.5765e-26, 5.8554e-32],\n",
            "       device='cuda:0'), Label: -1\n",
            "Input: tensor([0.0000e+00, 1.0000e+00, 9.9095e-31, 5.5705e-34, 1.1713e-31, 2.1418e-28,\n",
            "        3.5436e-34, 1.8477e-32, 6.0951e-34, 4.1409e-31, 1.4217e-38],\n",
            "       device='cuda:0'), Label: -1\n",
            "Input: tensor([0.0000e+00, 1.0000e+00, 1.2417e-40, 5.6052e-45, 9.2444e-42, 1.9420e-37,\n",
            "        2.8026e-45, 7.8893e-43, 5.6052e-45, 4.7162e-41, 0.0000e+00],\n",
            "       device='cuda:0'), Label: -1\n",
            "50000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**create final dataset for the attacker model**"
      ],
      "metadata": {
        "id": "n_EdcveEuO9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Combine the seen and unseen data\n",
        "def get_shadow_datasets(combined_in_data, combined_out_data):\n",
        "    # print(len(combined_in_data))\n",
        "    # print(len(combined_out_data))\n",
        "    combined_dataset = combined_in_data + combined_out_data\n",
        "    shuffle(combined_dataset)\n",
        "    # print(len(combined_dataset))\n",
        "\n",
        "    # Step 2: Split 60,000 data into 50,000 (train/validation) and 10,000 (test)\n",
        "    train_val_data = combined_dataset[:50000]\n",
        "    test_data = combined_dataset[50000:]\n",
        "\n",
        "    # Step 3: Further split train_val_data into 45,000 (train) and 5,000 (validation)\n",
        "    train_data = train_val_data[:45000]\n",
        "    val_data = train_val_data[45000:]\n",
        "\n",
        "    # Create DataLoaders\n",
        "    batch_size = 64\n",
        "\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "train_shadow_loader, val_shadow_loader, test_shadow_loader = get_shadow_datasets(combined_in_data, combined_out_data)\n",
        "\n",
        "# Example: Print sizes to verify\n",
        "# print(f\"Total Combined Dataset Size: {len(combined_dataset)}\")\n",
        "print(f\"Training Data Size: {len(train_shadow_loader)}\")\n",
        "print(f\"Validation Data Size: {len(val_shadow_loader)}\")\n",
        "print(f\"Test Data Size: {len(test_shadow_loader)}\")"
      ],
      "metadata": {
        "id": "NAv6q2zZY-ta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb973a13-4370-45f8-fd0b-dbca38576172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Size: 704\n",
            "Validation Data Size: 79\n",
            "Test Data Size: 157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**see a sample data**"
      ],
      "metadata": {
        "id": "5Bn6zuWeuiS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'sample train data: {train_shadow_loader.dataset[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLrRv2mPG7m0",
        "outputId": "6a58f434-df47-4ae3-da07-bc15bbd10a17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample train data: (tensor([6.0000e+00, 0.0000e+00, 2.9567e-42, 0.0000e+00, 0.0000e+00, 2.9937e-41,\n",
            "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "       device='cuda:0'), -1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**preprocess data to train linear regression model as attacker model**"
      ],
      "metadata": {
        "id": "3Hwngm2uvV8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract data and labels from DataLoader\n",
        "def extract_data_and_labels(loader):\n",
        "    data = []\n",
        "    labels = []\n",
        "    for x,y in loader:\n",
        "        data.append(x.cpu().numpy())  # Assuming DataLoader returns PyTorch tensors\n",
        "        labels.append(y.cpu().numpy())\n",
        "    data = np.concatenate(data, axis=0)\n",
        "    labels = np.concatenate(labels, axis=0)\n",
        "    # normalizing\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(data)\n",
        "    scaled_data = scaler.transform(data)\n",
        "    return scaled_data, labels\n",
        "\n",
        "X_train, y_train = extract_data_and_labels(train_shadow_loader)\n",
        "X_val, y_val = extract_data_and_labels(val_shadow_loader)\n",
        "X_test, y_test = extract_data_and_labels(test_shadow_loader)"
      ],
      "metadata": {
        "id": "IjyJbzhMWaxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**simple linear regression model as attacker**"
      ],
      "metadata": {
        "id": "kEQ62GPDvliJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LR()\n",
        "lr.fit(X_train, y_train)\n",
        "# Evaluate the model\n",
        "y_pred = lr.predict(X_test)"
      ],
      "metadata": {
        "id": "xQxOdjNCXPWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**check attacker model accuracy**"
      ],
      "metadata": {
        "id": "tp_4LwlxvvAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3K6_-ltvuJB",
        "outputId": "1dd213b1-135a-44fe-fb1a-a8df8ff1572f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 83.63%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**create private shadow models to mimic private model**"
      ],
      "metadata": {
        "id": "oj2GkIMBvzzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train 10 different shadow models, each with its corresponding label dataset\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "private_shadow_models = {}\n",
        "regularization_strength = 5e-3\n",
        "num_epochs = 5\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for label in range(10):\n",
        "    private_shadow_model = Private_ShadowModel().to(device)\n",
        "    print(f\"Training shadow model for label {label}...\")\n",
        "    model_train(private_shadow_model, train_loaders_by_label[label], val_loaders_by_label[label], criterion, num_epochs, regularization_strength)\n",
        "    private_shadow_models[label] = private_shadow_model\n",
        "\n",
        "# Save the shadow models\n",
        "for label in range(10):\n",
        "    torch.save(private_shadow_models[label].state_dict(), f'private_shadow_model_{label}.pth')\n",
        "\n",
        "# Example: Print summary of one shadow model\n",
        "print(private_shadow_models[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U0zm7YWZwcc",
        "outputId": "52aa4a06-6fbd-48ab-b50e-620a26dcffcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training shadow model for label 0...\n",
            "[Epoch 0]\t[00:13:35]\tTrain Loss: 0.9489\tTrain Accuracy: 0.98\tValidation Loss: 0.3545\t\tValidation Accuracy: 1.00\n",
            "[Epoch 1]\t[00:13:35]\tTrain Loss: 0.2338\tTrain Accuracy: 1.00\tValidation Loss: 0.1461\t\tValidation Accuracy: 1.00\n",
            "[Epoch 2]\t[00:13:36]\tTrain Loss: 0.1174\tTrain Accuracy: 1.00\tValidation Loss: 0.0913\t\tValidation Accuracy: 1.00\n",
            "[Epoch 3]\t[00:13:36]\tTrain Loss: 0.0854\tTrain Accuracy: 1.00\tValidation Loss: 0.0755\t\tValidation Accuracy: 1.00\n",
            "[Epoch 4]\t[00:13:36]\tTrain Loss: 0.0753\tTrain Accuracy: 1.00\tValidation Loss: 0.0701\t\tValidation Accuracy: 1.00\n",
            "Training shadow model for label 1...\n",
            "[Epoch 0]\t[00:13:37]\tTrain Loss: 0.8505\tTrain Accuracy: 0.99\tValidation Loss: 0.2999\t\tValidation Accuracy: 1.00\n",
            "[Epoch 1]\t[00:13:37]\tTrain Loss: 0.1928\tTrain Accuracy: 1.00\tValidation Loss: 0.1180\t\tValidation Accuracy: 1.00\n",
            "[Epoch 2]\t[00:13:37]\tTrain Loss: 0.0964\tTrain Accuracy: 1.00\tValidation Loss: 0.0754\t\tValidation Accuracy: 1.00\n",
            "[Epoch 3]\t[00:13:38]\tTrain Loss: 0.0734\tTrain Accuracy: 1.00\tValidation Loss: 0.0648\t\tValidation Accuracy: 1.00\n",
            "[Epoch 4]\t[00:13:38]\tTrain Loss: 0.0675\tTrain Accuracy: 1.00\tValidation Loss: 0.0628\t\tValidation Accuracy: 1.00\n",
            "Training shadow model for label 2...\n",
            "[Epoch 0]\t[00:13:38]\tTrain Loss: 0.8858\tTrain Accuracy: 0.99\tValidation Loss: 0.3093\t\tValidation Accuracy: 1.00\n",
            "[Epoch 1]\t[00:13:39]\tTrain Loss: 0.2040\tTrain Accuracy: 1.00\tValidation Loss: 0.1301\t\tValidation Accuracy: 1.00\n",
            "[Epoch 2]\t[00:13:39]\tTrain Loss: 0.1077\tTrain Accuracy: 1.00\tValidation Loss: 0.0870\t\tValidation Accuracy: 1.00\n",
            "[Epoch 3]\t[00:13:40]\tTrain Loss: 0.0832\tTrain Accuracy: 1.00\tValidation Loss: 0.0759\t\tValidation Accuracy: 1.00\n",
            "[Epoch 4]\t[00:13:40]\tTrain Loss: 0.0759\tTrain Accuracy: 1.00\tValidation Loss: 0.0711\t\tValidation Accuracy: 1.00\n",
            "Training shadow model for label 3...\n",
            "[Epoch 0]\t[00:13:40]\tTrain Loss: 0.9337\tTrain Accuracy: 0.98\tValidation Loss: 0.3142\t\tValidation Accuracy: 1.00\n",
            "[Epoch 1]\t[00:13:41]\tTrain Loss: 0.2081\tTrain Accuracy: 1.00\tValidation Loss: 0.1325\t\tValidation Accuracy: 1.00\n",
            "[Epoch 2]\t[00:13:41]\tTrain Loss: 0.1103\tTrain Accuracy: 1.00\tValidation Loss: 0.0893\t\tValidation Accuracy: 1.00\n",
            "[Epoch 3]\t[00:13:41]\tTrain Loss: 0.0850\tTrain Accuracy: 1.00\tValidation Loss: 0.0749\t\tValidation Accuracy: 1.00\n",
            "[Epoch 4]\t[00:13:42]\tTrain Loss: 0.0756\tTrain Accuracy: 1.00\tValidation Loss: 0.0689\t\tValidation Accuracy: 1.00\n",
            "Training shadow model for label 4...\n",
            "[Epoch 0]\t[00:13:42]\tTrain Loss: 1.0306\tTrain Accuracy: 0.94\tValidation Loss: 0.3367\t\tValidation Accuracy: 1.00\n",
            "[Epoch 1]\t[00:13:42]\tTrain Loss: 0.2284\tTrain Accuracy: 1.00\tValidation Loss: 0.1506\t\tValidation Accuracy: 1.00\n",
            "[Epoch 2]\t[00:13:42]\tTrain Loss: 0.1253\tTrain Accuracy: 1.00\tValidation Loss: 0.0992\t\tValidation Accuracy: 1.00\n",
            "[Epoch 3]\t[00:13:43]\tTrain Loss: 0.0936\tTrain Accuracy: 1.00\tValidation Loss: 0.0846\t\tValidation Accuracy: 1.00\n",
            "[Epoch 4]\t[00:13:43]\tTrain Loss: 0.0826\tTrain Accuracy: 1.00\tValidation Loss: 0.0774\t\tValidation Accuracy: 1.00\n",
            "Training shadow model for label 5...\n",
            "[Epoch 0]\t[00:13:43]\tTrain Loss: 0.9149\tTrain Accuracy: 0.97\tValidation Loss: 0.3090\t\tValidation Accuracy: 1.00\n",
            "[Epoch 1]\t[00:13:44]\tTrain Loss: 0.2022\tTrain Accuracy: 1.00\tValidation Loss: 0.1289\t\tValidation Accuracy: 1.00\n",
            "[Epoch 2]\t[00:13:44]\tTrain Loss: 0.1060\tTrain Accuracy: 1.00\tValidation Loss: 0.0869\t\tValidation Accuracy: 1.00\n",
            "[Epoch 3]\t[00:13:44]\tTrain Loss: 0.0819\tTrain Accuracy: 1.00\tValidation Loss: 0.0716\t\tValidation Accuracy: 1.00\n",
            "[Epoch 4]\t[00:13:45]\tTrain Loss: 0.0735\tTrain Accuracy: 1.00\tValidation Loss: 0.0672\t\tValidation Accuracy: 1.00\n",
            "Training shadow model for label 6...\n",
            "[Epoch 0]\t[00:13:45]\tTrain Loss: 0.8825\tTrain Accuracy: 0.98\tValidation Loss: 0.3203\t\tValidation Accuracy: 1.00\n",
            "[Epoch 1]\t[00:13:45]\tTrain Loss: 0.2120\tTrain Accuracy: 1.00\tValidation Loss: 0.1357\t\tValidation Accuracy: 1.00\n",
            "[Epoch 2]\t[00:13:46]\tTrain Loss: 0.1107\tTrain Accuracy: 1.00\tValidation Loss: 0.0885\t\tValidation Accuracy: 1.00\n",
            "[Epoch 3]\t[00:13:46]\tTrain Loss: 0.0841\tTrain Accuracy: 1.00\tValidation Loss: 0.0747\t\tValidation Accuracy: 1.00\n",
            "[Epoch 4]\t[00:13:46]\tTrain Loss: 0.0744\tTrain Accuracy: 1.00\tValidation Loss: 0.0700\t\tValidation Accuracy: 1.00\n",
            "Training shadow model for label 7...\n",
            "[Epoch 0]\t[00:13:47]\tTrain Loss: 0.8573\tTrain Accuracy: 0.99\tValidation Loss: 0.3034\t\tValidation Accuracy: 1.00\n",
            "[Epoch 1]\t[00:13:47]\tTrain Loss: 0.1981\tTrain Accuracy: 1.00\tValidation Loss: 0.1277\t\tValidation Accuracy: 1.00\n",
            "[Epoch 2]\t[00:13:47]\tTrain Loss: 0.1029\tTrain Accuracy: 1.00\tValidation Loss: 0.0844\t\tValidation Accuracy: 1.00\n",
            "[Epoch 3]\t[00:13:48]\tTrain Loss: 0.0780\tTrain Accuracy: 1.00\tValidation Loss: 0.0715\t\tValidation Accuracy: 1.00\n",
            "[Epoch 4]\t[00:13:48]\tTrain Loss: 0.0705\tTrain Accuracy: 1.00\tValidation Loss: 0.0668\t\tValidation Accuracy: 1.00\n",
            "Training shadow model for label 8...\n",
            "[Epoch 0]\t[00:13:49]\tTrain Loss: 0.9032\tTrain Accuracy: 1.00\tValidation Loss: 0.3184\t\tValidation Accuracy: 1.00\n",
            "[Epoch 1]\t[00:13:49]\tTrain Loss: 0.2040\tTrain Accuracy: 1.00\tValidation Loss: 0.1248\t\tValidation Accuracy: 1.00\n",
            "[Epoch 2]\t[00:13:49]\tTrain Loss: 0.1023\tTrain Accuracy: 1.00\tValidation Loss: 0.0817\t\tValidation Accuracy: 1.00\n",
            "[Epoch 3]\t[00:13:50]\tTrain Loss: 0.0776\tTrain Accuracy: 1.00\tValidation Loss: 0.0688\t\tValidation Accuracy: 1.00\n",
            "[Epoch 4]\t[00:13:50]\tTrain Loss: 0.0699\tTrain Accuracy: 1.00\tValidation Loss: 0.0656\t\tValidation Accuracy: 1.00\n",
            "Training shadow model for label 9...\n",
            "[Epoch 0]\t[00:13:50]\tTrain Loss: 0.8391\tTrain Accuracy: 0.99\tValidation Loss: 0.2883\t\tValidation Accuracy: 1.00\n",
            "[Epoch 1]\t[00:13:51]\tTrain Loss: 0.1840\tTrain Accuracy: 1.00\tValidation Loss: 0.1131\t\tValidation Accuracy: 1.00\n",
            "[Epoch 2]\t[00:13:51]\tTrain Loss: 0.0927\tTrain Accuracy: 1.00\tValidation Loss: 0.0741\t\tValidation Accuracy: 1.00\n",
            "[Epoch 3]\t[00:13:51]\tTrain Loss: 0.0716\tTrain Accuracy: 1.00\tValidation Loss: 0.0642\t\tValidation Accuracy: 1.00\n",
            "[Epoch 4]\t[00:13:52]\tTrain Loss: 0.0661\tTrain Accuracy: 1.00\tValidation Loss: 0.0631\t\tValidation Accuracy: 1.00\n",
            "Private_ShadowModel(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (dropout1): Dropout(p=0.25, inplace=False)\n",
            "  (dropout2): Dropout(p=0.5, inplace=False)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=6272, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**read saved private shadow models and prepare data for attacker model**"
      ],
      "metadata": {
        "id": "m7Vav6O2v66y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the dictionary for the shadow models\n",
        "private_shadow_models = {}\n",
        "\n",
        "model_dir = './'\n",
        "\n",
        "# Load shadow models\n",
        "for i in range(10):\n",
        "    model_path = os.path.join(model_dir, f'private_shadow_model_{i}.pth')\n",
        "    private_shadow_model = Private_ShadowModel().to(device)\n",
        "    private_shadow_model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    private_shadow_model.eval()  # Set the model to evaluation mode\n",
        "    private_shadow_models[i] = private_shadow_model\n",
        "\n",
        "# Example: Print the keys of the shadow_models dictionary to verify\n",
        "print(\"Loaded private shadow models:\", private_shadow_models.keys())\n",
        "\n",
        "# Create seen data\n",
        "private_combined_in_data1 = list(create_combined_data(private_shadow_models, train_loaders_by_label, 1))\n",
        "private_combined_in_data2 = list(create_combined_data(private_shadow_models, val_loaders_by_label, 1))\n",
        "private_combined_in_data = private_combined_in_data1 + private_combined_in_data2\n",
        "\n",
        "# Create unseen data\n",
        "private_combined_out_data = list(create_combined_data(private_shadow_models, test_loaders_by_label, -1))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqBP12Q7aW99",
        "outputId": "a94b410d-a5fe-44e9-ecd1-0a7a7bf620b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded private shadow models: dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**see samples of final data**"
      ],
      "metadata": {
        "id": "wp1c80Qnv_k6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Print first few entries of each data\n",
        "for i in range(5):\n",
        "    input_data, label = private_combined_in_data[i]\n",
        "    print(f\"Input: {input_data}, Label: {label}\")\n",
        "\n",
        "for i in range(5):\n",
        "    input_data, label = private_combined_out_data[i]\n",
        "    print(f\"Input: {input_data}, Label: {label}\")\n",
        "\n",
        "print(len(private_combined_in_data))\n",
        "print(len(private_combined_out_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie4fH-1SbT0S",
        "outputId": "d1f0e7da-bf9c-4ab4-dd5e-e4c1258c5755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: tensor([ 0.0000,  8.8220, -0.0367,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         0.0000,  0.0000,  0.0000], device='cuda:0'), Label: 1\n",
            "Input: tensor([ 0.0000,  9.0015, -0.0374,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         0.0000,  0.0000,  0.0000], device='cuda:0'), Label: 1\n",
            "Input: tensor([ 0.0000,  7.0305, -0.0292,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         0.0000,  0.0000,  0.0000], device='cuda:0'), Label: 1\n",
            "Input: tensor([ 0.0000,  7.8352, -0.0327,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         0.0000,  0.0000,  0.0000], device='cuda:0'), Label: 1\n",
            "Input: tensor([ 0.0000,  7.1656, -0.0298,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         0.0000,  0.0000,  0.0000], device='cuda:0'), Label: 1\n",
            "Input: tensor([ 0.0000,  8.0605, -0.0335,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         0.0000,  0.0000,  0.0000], device='cuda:0'), Label: -1\n",
            "Input: tensor([ 0.0000,  8.8565, -0.0368,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         0.0000,  0.0000,  0.0000], device='cuda:0'), Label: -1\n",
            "Input: tensor([ 0.0000,  7.1190, -0.0296,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         0.0000,  0.0000,  0.0000], device='cuda:0'), Label: -1\n",
            "Input: tensor([ 0.0000,  8.8023, -0.0366,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         0.0000,  0.0000,  0.0000], device='cuda:0'), Label: -1\n",
            "Input: tensor([ 0.0000, 10.5370, -0.0438,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         0.0000,  0.0000,  0.0000], device='cuda:0'), Label: -1\n",
            "50000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**combine in and out datas**"
      ],
      "metadata": {
        "id": "AbYRXfSdwIdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "private_train_shadow_loader, private_val_shadow_loader, private_test_shadow_loader = get_shadow_datasets(private_combined_in_data, private_combined_out_data)\n",
        "\n",
        "# Example: Print sizes to verify\n",
        "# print(f\"Total Combined Dataset Size: {len(combined_dataset)}\")\n",
        "print(f\"Training Data Size: {len(private_train_shadow_loader)}\")\n",
        "print(f\"Validation Data Size: {len(private_val_shadow_loader)}\")\n",
        "print(f\"Test Data Size: {len(private_test_shadow_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-OnJpp3bakY",
        "outputId": "0b701899-3ed5-4d77-a441-923d1ff73fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Size: 704\n",
            "Validation Data Size: 79\n",
            "Test Data Size: 157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**private attacker model sample train data**"
      ],
      "metadata": {
        "id": "sHqAxZzswaBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'sample train data: {private_train_shadow_loader.dataset[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb_I_AzqcWGt",
        "outputId": "610090ef-bb4d-46f8-e8c6-727bffaf532d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample train data: (tensor([ 0.0000,  8.7030, -0.0361,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         0.0000,  0.0000,  0.0000], device='cuda:0'), 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Seperate parts of data for linear regression model**"
      ],
      "metadata": {
        "id": "iFC03daHwcaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract data and labels from DataLoader\n",
        "private_X_train, private_y_train = extract_data_and_labels(private_train_shadow_loader)\n",
        "private_X_val, private_y_val = extract_data_and_labels(private_val_shadow_loader)\n",
        "private_X_test, private_y_test = extract_data_and_labels(private_test_shadow_loader)"
      ],
      "metadata": {
        "id": "Z_DZmztOcaFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train linear regression attacker model for private dataset**"
      ],
      "metadata": {
        "id": "-iXZXtEBwjba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LR()\n",
        "lr.fit(private_X_train, private_y_train)\n",
        "# Evaluate the model\n",
        "private_y_pred = lr.predict(private_X_test)"
      ],
      "metadata": {
        "id": "5fcvDuSeciwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**check accuracy of private attacker model**"
      ],
      "metadata": {
        "id": "QHGp7CoawoXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(private_y_test, private_y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdgUcNRzwo28",
        "outputId": "9dbcb4eb-88bd-48c6-b9d9-0377ffa44ef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 82.71%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2bIcE-JPZ8m"
      },
      "outputs": [],
      "source": [
        "# class AttackerModel(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(AttackerModel, self).__init__()\n",
        "#         self.fc1 = nn.Linear(11, 128)\n",
        "#         self.fc2 = nn.Linear(128, 64)\n",
        "#         self.fc3 = nn.Linear(64, 32)\n",
        "#         self.fc4 = nn.Linear(32, 1)\n",
        "#         self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = torch.relu(self.fc1(x))\n",
        "#         x = torch.relu(self.fc2(x))\n",
        "#         x = torch.relu(self.fc3(x))\n",
        "#         x = self.sigmoid(self.fc4(x))\n",
        "#         return x\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}